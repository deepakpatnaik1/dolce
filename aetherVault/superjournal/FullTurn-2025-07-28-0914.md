---
timestamp: 2025-07-28 07:14:53 +0000
persona: claude
---

Boss: Claude, write me a python script to count the number of tokens in a file on my hard disk and tell me how to run it.

claude: ðŸ¦§

Here's a Python script to count tokens in a file. I'll provide two versions - one using simple whitespace splitting and another using a proper tokenizer library.

## Simple Version (whitespace-based)

```python
#!/usr/bin/env python3
"""
Token counter script - counts tokens in a text file
Usage: python token_counter.py <filename>
"""

import sys
import os

def count_tokens_simple(filename):
    """Count tokens using whitespace splitting"""
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            content = file.read()
            tokens = content.split()
            return len(tokens)
    except FileNotFoundError:
        print(f"Error: File '{filename}' not found")
        return None
    except Exception as e:
        print(f"Error reading file: {e}")
        return None

def main():
    if len(sys.argv) != 2:
        print("Usage: python token_counter.py <filename>")
        sys.exit(1)
    
    filename = sys.argv[1]
    
    if not os.path.exists(filename):
        print(f"Error: File '{filename}' does not exist")
        sys.exit(1)
    
    token_count = count_tokens_simple(filename)
    
    if token_count is not None:
        print(f"File: {filename}")
        print(f"Token count: {token_count:,}")

if __name__ == "__main__":
    main()
```

## Advanced Version (using tiktoken for GPT-style tokens)

```python
#!/usr/bin/env python3
"""
Advanced token counter - supports multiple tokenization methods
Usage: python advanced_token_counter.py <filename> [--method simple|gpt]
"""

import sys
import os
import argparse

def count_tokens_simple(text):
    """Count tokens using whitespace splitting"""
    return len(text.split())

def count_tokens_gpt(text):
    """Count tokens using GPT tokenizer (requires tiktoken)"""
    try:
        import tiktoken
        encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
        tokens = encoding.encode(text)
        return len(tokens)
    except ImportError:
        print("Error: tiktoken not installed. Install with: pip install tiktoken")
        return None

def main():
    parser = argparse.ArgumentParser(description='Count tokens in a text file')
    parser.add_argument('filename', help='Path to the text file')
    parser.add_argument('--method', choices=['simple', 'gpt'], default='simple',
                       help='Tokenization method (default: simple)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.filename):
        print(f"Error: File '{args.filename}' does not exist")
        sys.exit(1)
    
    try:
        with open(args.filename, 'r', encoding='utf-8') as file:
            content = file.read()
    except Exception as e:
        print(f"Error reading file: {e}")
        sys.exit(1)
    
    if args.method == 'simple':
        token_count = count_tokens_simple(content)
    elif args.method == 'gpt':
        token_count = count_tokens_gpt(content)
        if token_count is None:
            sys.exit(1)
    
    print(f"File: {args.filename}")
    print(f"Method: {args.method}")
    print(f"Token count: {token_count:,}")
    print(f"Character count: {len(content):,}")
    print(f"Word count: {len(content.split()):,}")

if __name__ == "__main__":
    main()
```

## How to Run

1. **Save the script** to a file (e.g., `token_counter.py`)

2. **Make it executable** (optional on Unix systems):
   ```bash
   chmod +x token_counter.py
   ```

3. **Run the simple version**:
   ```bash
   python token_counter.py /path/to/your/file.txt
   ```

4. **Run the advanced version**:
   ```bash
   # Simple tokenization
   python advanced_token_counter.py /path/to/your/file.txt
   
   # GPT-style tokenization (requires tiktoken)
   python advanced_token_counter.py /path/to/your/file.txt --method gpt
   ```

5. **Install tiktoken** (for GPT tokenization):
   ```bash
   pip install tiktoken
   ```

## Example Output

```
File: example.txt
Method: simple
Token count: 1,245
Character count: 6,789
Word count: 1,245
```

The simple version counts whitespace-separated words. The advanced version can also count GPT-style tokens, which is useful for estimating API costs or context limits.